# 04. Linear Regression with Multiple Variables

### 1. Linear regression with multiple features

*여러 개의 features를 갖는 새로운 버전의 linear regression*

- 여러 개의 변수 = 여러 개의 features
- 원래 단순한 linear regression에서는
  - X = 집의 크기 (이것을 이용하여 예측)
  - y = 집의 가격
- 더 많은 변수를 갖는 새로운 scheme에서는 (침실의 수, 층수, 집의 연식 등)
  - x1, x2, x3, x4 : 4개의 features
    - x1는 집의 크기 (feet squared)
    - x2는 침실의 수
    - x3는 층수
    - x4는 집의 연식 (years)
  - y는 출력 변수 (가격)
- 추가된 표기법
  - $^n$
    - features의 숫자 (n = 4)
  - $m$
    - examples의 수 (테이블 행의 개수)
  - $x^i$
    - examples에 대한 입력 벡터 (i번째 example에 대한 네 개의 파라미터의 벡터)
    - i는 training set에서의 인덱스
    - x는 n-차원의 feature vector
    - 예를 들어, $x^3$는 3번 째 집이고 그 집에 관련된 네 가지의 features가 포함되어 있다
  - $x_j^i$
    - i번째 training example에서의 feature j의 값
    - 예를 들어, $x_s^3$은 3번 째 집의 침실의 수이다.
- 이제 여러 개의 features를 갖고 있다
  - hypothesis의 형식은 어떻게 되는 가?
  - 이전의 하나의 feature를 갖는 hypothesis가 가지는 형식
    - $h_\theta(x) = \theta_0 + \theta_1x$
      - 여기에는 cost function에 의해 결정된 2개의 파라미터가 있다. ($\theta_0, \theta_1$)
      - 하나의 변수 $x$
  - 여러 개의 features를 가지는 경우
    - $h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_3 + \theta_4 x_4$
    - 예를 들어
      - $h_\theta(x) = 80 + 0.1x_1 + 0.01x_2 + 3x_3 -2x_4$
        - 집 가격을 예측하는 hypothesis이다
        - 파라미터들은 여전히 cost function에 의해서 결정된다
  - 표기의 편의를 위해서 $x_0 = 1$이라고 하고
    - 모든 examples i는 각 example에 대해 추가적인 0번 째 feature를 가지고 있다.
    - 그래서 *feature vector*는 인덱스가 0부터 시작하는 n+1차원의 feature vector이다.
      - x라고 불리는 column vector이다
      - 각 example는 각자와 관련된 column vector가 있다
      - 이제부터 새로운 example를 "X"라고 부르자
    - *파라미터*도 인덱스가 0부터 시작해서 n+1차원의 벡터다
      - $\theta$라고 부르는 column vector
      - 이 벡터는 모든 example에 대해 같은 값을 갖는다
  - 이런 것들을 고려한다면, hypothesis는 이렇게 쓸 수 있다
    - $h_\theta(x) = \theta_0x_0 + \theta_1x_0 + \theta_2x_2 + \theta_3x_3 + \theta_4x_4$
  - 만약 이렇게 한다면
    - $h_\theta(x) = \theta^TX$
      - $\theta^T$는 [1 x n+1] 행렬
      - 즉, $\theta$는 column vector이기 때문에 전치행렬 연산을 통해 row vector로 만들어 주어야 한다
      - 원래 행렬 $\theta$ = n+1 x 1 행렬
      - 전치 행렬 $\theta^T$ = 1 x n+1 행렬
      - 저 식의 의미는 $\theta^T과 \;X$의 안쪽 차원이 같기 때문에 곱셈을 할 수 있다
        - [1 x n+1] * [n+1 x 1] = $h_\theta(x)$
        - 그래서 전치한 파라미터 행렬과 입력  example는 [1 x 1]차원의 예측된 hypothesis를 출력한다
    - $x_0 = 1$는 이렇게 쓸 수 있도록 해준다
  - 여러 개의 변수를 갖는 linear regression의 예이다



---

### 2. Gradient descent for multiple variables

- gradient descent하면서 hypothesis에 파라미터들을 맞춘다
  - 파라미터는 $\theta_0$~$\theta_n$
  - 

